{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMPPjx4AwmvTsGf7ZHD9xj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rosanth/Recommended_Sys/blob/Sajeevan/Reco_Sys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "id": "c5bsomlsr-LU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "import fitz"
      ],
      "metadata": {
        "id": "kHwScmPSr_6S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Sample job requirements (Multiple examples for better training)\n",
        "job_descriptions = [\n",
        "    \"Looking for a candidate with knowledge in Python, Java, and Power BI.\",\n",
        "    \"Seeking a Data Analyst with Power BI and SQL experience.\",\n",
        "    \"Need a software engineer with knowledge in Java and Python.\",\n",
        "    \"Hiring a business analyst skilled in Excel and Power BI.\",\n",
        "    \"Need Cloud based Knowledge\"\n",
        "]\n",
        "\n",
        "# Corresponding labels (1 = Suitable, 0 = Not Suitable)\n",
        "labels = [1, 1, 1, 1, 0]\n",
        "\n",
        "# Preprocess job descriptions\n",
        "job_descriptions = [preprocess_text(desc) for desc in job_descriptions]\n",
        "\n",
        "# Tokenization\n",
        "max_words = 1000  # Max unique words in vocab\n",
        "max_length = 100  # Max sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(job_descriptions)\n",
        "\n",
        "# Convert job descriptions to sequences\n",
        "X_train = tokenizer.texts_to_sequences(job_descriptions)\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
        "\n",
        "y_train = np.array(labels)\n",
        "\n",
        "# Define the Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=32, input_length=max_length),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=2, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Load and extract resume text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# Clean and preprocess resume text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w.,]', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Function to evaluate a resume\n",
        "def evaluate_resume(resume_text):\n",
        "    resume_text = preprocess_text(resume_text)\n",
        "    input_data = tokenizer.texts_to_sequences([resume_text])\n",
        "    input_data = pad_sequences(input_data, maxlen=max_length, padding='post')\n",
        "\n",
        "    prediction = model.predict(input_data)[0][0]\n",
        "\n",
        "    return \"Resume is suitable for the job.\" if prediction > 0.7 else \"Resume is not suitable for the job.\"\n",
        "\n",
        "# Example usage: Extract, clean, and evaluate resume\n",
        "pdf_path = \"Sajeevan.pdf\"  # Change this to your PDF file name\n",
        "resume_text = extract_text_from_pdf(pdf_path)\n",
        "resume_text = clean_text(resume_text)\n",
        "\n",
        "# Print evaluation result\n",
        "print(evaluate_resume(resume_text))\n"
      ],
      "metadata": {
        "id": "dnhIEVCRyaME"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}